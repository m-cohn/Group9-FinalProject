{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>age_onset</th>\n",
       "      <th>birthplace</th>\n",
       "      <th>filename</th>\n",
       "      <th>native_language</th>\n",
       "      <th>sex</th>\n",
       "      <th>speakerid</th>\n",
       "      <th>country</th>\n",
       "      <th>file_missing?</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>koussi, senegal</td>\n",
       "      <td>balanta</td>\n",
       "      <td>balanta</td>\n",
       "      <td>male</td>\n",
       "      <td>788</td>\n",
       "      <td>senegal</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>buea, cameroon</td>\n",
       "      <td>cameroon</td>\n",
       "      <td>cameroon</td>\n",
       "      <td>male</td>\n",
       "      <td>1953</td>\n",
       "      <td>cameroon</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>hong, adamawa, nigeria</td>\n",
       "      <td>fulfulde</td>\n",
       "      <td>fulfulde</td>\n",
       "      <td>male</td>\n",
       "      <td>1037</td>\n",
       "      <td>nigeria</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>port-au-prince, haiti</td>\n",
       "      <td>haitian</td>\n",
       "      <td>haitian</td>\n",
       "      <td>male</td>\n",
       "      <td>1165</td>\n",
       "      <td>haiti</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>port-au-prince, haiti</td>\n",
       "      <td>haitian</td>\n",
       "      <td>haitian</td>\n",
       "      <td>male</td>\n",
       "      <td>1166</td>\n",
       "      <td>haiti</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  age_onset              birthplace  filename native_language   sex   \n",
       "0  24.0       12.0         koussi, senegal   balanta         balanta  male  \\\n",
       "1  18.0       10.0          buea, cameroon  cameroon        cameroon  male   \n",
       "2  48.0        8.0  hong, adamawa, nigeria  fulfulde        fulfulde  male   \n",
       "3  42.0       42.0   port-au-prince, haiti   haitian         haitian  male   \n",
       "4  40.0       35.0   port-au-prince, haiti   haitian         haitian  male   \n",
       "\n",
       "   speakerid   country  file_missing?  Unnamed: 9  Unnamed: 10 Unnamed: 11  \n",
       "0        788   senegal           True         NaN          NaN         NaN  \n",
       "1       1953  cameroon           True         NaN          NaN         NaN  \n",
       "2       1037   nigeria           True         NaN          NaN         NaN  \n",
       "3       1165     haiti           True         NaN          NaN         NaN  \n",
       "4       1166     haiti           True         NaN          NaN         NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert csv to dataframe\n",
    "df = pd.read_csv('speakers_all.csv')\n",
    "\n",
    "# Display the first 5 rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "native_language\n",
      "english     579\n",
      "spanish     162\n",
      "arabic      102\n",
      "mandarin     65\n",
      "french       63\n",
      "           ... \n",
      "kalanga       1\n",
      "kabyle        1\n",
      "jola          1\n",
      "irish         1\n",
      "zulu          1\n",
      "Name: count, Length: 214, dtype: int64\n",
      "country\n",
      "usa         393\n",
      "china        88\n",
      "uk           67\n",
      "india        59\n",
      "canada       54\n",
      "           ... \n",
      "namibia       1\n",
      "romanian      1\n",
      "burundi       1\n",
      "rwanda        1\n",
      "benin         1\n",
      "Name: count, Length: 176, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print distribution of native_language, and country\n",
    "print(df['native_language'].value_counts())\n",
    "print(df['country'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of english:  579\n",
      "Number of non-english:  1559\n",
      "Total number of files:  2172\n",
      "Number of english:  579\n",
      "Number of non-english:  780\n"
     ]
    }
   ],
   "source": [
    "# Create two classes of data, USA and non-USA, and grab the filenames of both classes\n",
    "# Also make sure the file_missing? column is False\n",
    "english = df[(df['native_language'] == 'english') & (df['file_missing?'] == False)]['filename']\n",
    "non_english = df[(df['native_language'] != 'english') & (df['file_missing?'] == False)]['filename']\n",
    "\n",
    "print('Number of english: ', len(english))\n",
    "print('Number of non-english: ', len(non_english))\n",
    "\n",
    "# Print total number of files\n",
    "print('Total number of files: ', len(df))\n",
    "\n",
    "# Create a list of countries that have less than 10 speakers\n",
    "native_languages = df['native_language'].value_counts()\n",
    "native_languages = native_languages[native_languages < 25].index.tolist()\n",
    "\n",
    "# Remove the countries that only have 1 speaker\n",
    "df = df[~df['native_language'].isin(native_languages)]\n",
    "\n",
    "english = df[(df['native_language'] == 'english') & (df['file_missing?'] == False)]['filename']\n",
    "non_english = df[(df['native_language'] != 'english') & (df['file_missing?'] == False)]['filename']\n",
    "\n",
    "print('Number of english: ', len(english))\n",
    "print('Number of non-english: ', len(non_english))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to calculate the spectrogram\n",
    "def calculate_spectrogram(audio_file, n_fft=2048, hop_length=512):\n",
    "    signal, sample_rate = librosa.load(audio_file)\n",
    "    spectrogram = librosa.stft(signal, n_fft=n_fft, hop_length=hop_length)\n",
    "    \n",
    "    return np.abs(spectrogram)\n",
    "\n",
    "def truncate_spectrogram(spectrogram, fixed_length):\n",
    "    truncated_spectrogram = spectrogram[:, :fixed_length]\n",
    "    return truncated_spectrogram\n",
    "\n",
    "def calculate_mel_spectrogram(audio_file, n_fft=2048, hop_length=512, n_mels=128):\n",
    "    signal, sample_rate = librosa.load(audio_file)\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=signal, sr=sample_rate, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
    "    \n",
    "    return mel_spectrogram\n",
    "\n",
    "def calculate_mel_spectrogram_no_load(signal, sample_rate, n_fft=2048, hop_length=512, n_mels=128):\n",
    "\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=signal, sr=sample_rate, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
    "    \n",
    "    return mel_spectrogram\n",
    "\n",
    "def normalize_spectrogram(spectrogram):\n",
    "    mean = np.mean(spectrogram)\n",
    "    std_dev = np.std(spectrogram)\n",
    "    normalized_spectrogram = (spectrogram - mean) / std_dev\n",
    "    return normalized_spectrogram\n",
    "\n",
    "def min_max_normalize_spectrogram(spectrogram):\n",
    "    min_value = np.min(spectrogram)\n",
    "    max_value = np.max(spectrogram)\n",
    "    normalized_spectrogram = (spectrogram - min_value) / (max_value - min_value)\n",
    "    return normalized_spectrogram\n",
    "\n",
    "def pitch_shift(audio_data, sample_rate, pitch_shift_steps):\n",
    "    return librosa.effects.pitch_shift(y=audio_data, sr=sample_rate, n_steps=pitch_shift_steps)\n",
    "\n",
    "def add_background_noise(audio_data, noise_amplitude):\n",
    "    noise = np.random.normal(0, noise_amplitude, len(audio_data))\n",
    "    return audio_data + noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "(1, 128, 709)\n",
      "(1, 128, 709)\n",
      "(1, 128, 709)\n",
      "(1, 128, 709)\n",
      "(1, 128, 709)\n",
      "(1, 128, 709)\n",
      "Size of english_spectros:  (579, 1, 128, 709)\n",
      "Size of non_english_spectros:  (780, 1, 128, 709)\n",
      "Size of augmented_spectros:  (4077, 1, 128, 709)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the spectrogram for all audio files in the english class\n",
    "english_spectro = []\n",
    "augmented_spectro = []\n",
    "augmented_labels = []\n",
    "i = 0\n",
    "for file in english:\n",
    "    # Check if file_name exists, if it doesn't, skip it\n",
    "    file_name = 'recordings/recordings/' + file + '.mp3'\n",
    "    if not os.path.exists(file_name):\n",
    "        continue\n",
    "\n",
    "    spectrogram = calculate_mel_spectrogram('recordings/recordings/' + file + '.mp3', n_fft=2048, hop_length=512)\n",
    "    english_spectro.append(spectrogram)\n",
    "\n",
    "    # Create a pitch shifted version of the spectrogram, first find the sampling rate\n",
    "    signal, sample_rate = librosa.load('recordings/recordings/' + file + '.mp3')\n",
    "    pitch_shifted_spectrogram = calculate_mel_spectrogram_no_load(signal=pitch_shift(signal, sample_rate, 2), sample_rate=sample_rate, n_fft=2048, hop_length=512)\n",
    "    \n",
    "    augmented_spectro.append(pitch_shifted_spectrogram)\n",
    "\n",
    "    # Add label to augmented_labels\n",
    "    augmented_labels.append(1)\n",
    "\n",
    "    # Create a noisy version of the spectrogram\n",
    "    noisy_spectrogram = calculate_mel_spectrogram_no_load(signal=add_background_noise(signal, 0.005), sample_rate=sample_rate, n_fft=2048, hop_length=512)\n",
    "    augmented_spectro.append(noisy_spectrogram)\n",
    "\n",
    "    # Add label to augmented_labels\n",
    "    augmented_labels.append(1)\n",
    "\n",
    "    # Create a noisy pitch shifted version of the spectrogram\n",
    "    noisy_pitch_shifted_spectrogram = calculate_mel_spectrogram_no_load(signal=add_background_noise(pitch_shift(signal, sample_rate, 2), 0.005), sample_rate=sample_rate, n_fft=2048, hop_length=512)\n",
    "    augmented_spectro.append(noisy_pitch_shifted_spectrogram)\n",
    "\n",
    "    # Add label to augmented_labels\n",
    "    augmented_labels.append(1)\n",
    "\n",
    "    # Add a counter to keep track of progress\n",
    "    i += 1\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "\n",
    "# Grab the spectros for all audio files in the non-english class\n",
    "non_english_spectro = []\n",
    "i = 0\n",
    "for file in non_english:\n",
    "    # Check if file_name exists, if it doesn't, skip it\n",
    "    file_name = 'recordings/recordings/' + file + '.mp3'\n",
    "    if not os.path.exists(file_name):\n",
    "        continue\n",
    "\n",
    "    spectrogram = calculate_mel_spectrogram('recordings/recordings/' + file + '.mp3', n_fft=2048, hop_length=512)\n",
    "    non_english_spectro.append(spectrogram)\n",
    "\n",
    "    # Create a pitch shifted version of the spectrogram, first find the sampling rate\n",
    "    signal, sample_rate = librosa.load('recordings/recordings/' + file + '.mp3')\n",
    "    pitch_shifted_spectrogram = calculate_mel_spectrogram_no_load(signal=pitch_shift(signal, sample_rate, 2), sample_rate=sample_rate, n_fft=2048, hop_length=512)\n",
    "    \n",
    "    augmented_spectro.append(pitch_shifted_spectrogram)\n",
    "\n",
    "    # Add label to augmented_labels\n",
    "    augmented_labels.append(0)\n",
    "\n",
    "    # Create a noisy version of the spectrogram\n",
    "    noisy_spectrogram = calculate_mel_spectrogram_no_load(signal=add_background_noise(signal, 0.005), sample_rate=sample_rate, n_fft=2048, hop_length=512)\n",
    "    augmented_spectro.append(noisy_spectrogram)\n",
    "\n",
    "    # Add label to augmented_labels\n",
    "    augmented_labels.append(0)\n",
    "\n",
    "    # Create a noisy pitch shifted version of the spectrogram\n",
    "    noisy_pitch_shifted_spectrogram = calculate_mel_spectrogram_no_load(signal=add_background_noise(pitch_shift(signal, sample_rate, 2), 0.005), sample_rate=sample_rate, n_fft=2048, hop_length=512)\n",
    "    augmented_spectro.append(noisy_pitch_shifted_spectrogram)\n",
    "\n",
    "    # Add label to augmented_labels\n",
    "    augmented_labels.append(0)\n",
    "\n",
    "    # Add a counter to keep track of progress\n",
    "    i += 1\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "\n",
    "\n",
    "# Calculate the minimum length of all spectrograms\n",
    "min_length = min([spectrogram.shape[1] for spectrogram in english_spectro + non_english_spectro + augmented_spectro])\n",
    "\n",
    "# Truncate each spectrogram in the english_spectro and non_english_spectro lists to the minimum length\n",
    "english_spectro = [truncate_spectrogram(spectrogram, min_length) for spectrogram in english_spectro]\n",
    "non_english_spectro = [truncate_spectrogram(spectrogram, min_length) for spectrogram in non_english_spectro]\n",
    "augmented_spectro = [truncate_spectrogram(spectrogram, min_length) for spectrogram in augmented_spectro]\n",
    "\n",
    "# Normalize each spectrogram in the english_spectro and non_english_spectro lists using min-max normalization\n",
    "english_spectro = [min_max_normalize_spectrogram(spectrogram) for spectrogram in english_spectro]\n",
    "non_english_spectro = [min_max_normalize_spectrogram(spectrogram) for spectrogram in non_english_spectro]\n",
    "augmented_spectro = [min_max_normalize_spectrogram(spectrogram) for spectrogram in augmented_spectro]\n",
    "\n",
    "# Add channel dimension as the first dimension to each spectrogram\n",
    "english_spectro = [np.expand_dims(spectrogram, axis=0) for spectrogram in english_spectro]\n",
    "non_english_spectro = [np.expand_dims(spectrogram, axis=0) for spectrogram in non_english_spectro]\n",
    "augmented_spectro = [np.expand_dims(spectrogram, axis=0) for spectrogram in augmented_spectro]\n",
    "\n",
    "# Convert the lists to numpy arrays\n",
    "english_spectro = np.array(english_spectro)\n",
    "non_english_spectro = np.array(non_english_spectro)\n",
    "augmented_spectro = np.array(augmented_spectro)\n",
    "\n",
    "# Print shapes of first and last spectrogram in both lists\n",
    "print(english_spectro[0].shape)\n",
    "print(english_spectro[-1].shape)\n",
    "\n",
    "print(non_english_spectro[0].shape)\n",
    "print(non_english_spectro[-1].shape)\n",
    "\n",
    "print(augmented_spectro[0].shape)\n",
    "print(augmented_spectro[-1].shape)\n",
    "\n",
    "# Print the shape of the arrays\n",
    "print(\"Size of english_spectros: \", english_spectro.shape)\n",
    "print(\"Size of non_english_spectros: \", non_english_spectro.shape)\n",
    "print(\"Size of augmented_spectros: \", augmented_spectro.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1359, 1, 128, 709)\n",
      "(1359,)\n"
     ]
    }
   ],
   "source": [
    "# Add a label of 1 to the english class, and 0 to the non-english class\n",
    "english_labels = np.ones(english_spectro.shape[0])\n",
    "non_english_labels = np.zeros(non_english_spectro.shape[0])\n",
    "augmented_labels = np.array(augmented_labels)\n",
    "\n",
    "# Combine the english and non-english data into one array\n",
    "X = np.concatenate((english_spectro, non_english_spectro))\n",
    "y = np.concatenate((english_labels, non_english_labels))\n",
    "\n",
    "# Print the shape of the combined array\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data to npz files\n",
    "np.savez('mel_spectro_data_min_max_norm_augmented.npz', X=X, y=y, X_augmented=augmented_spectro, y_augmented=augmented_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
